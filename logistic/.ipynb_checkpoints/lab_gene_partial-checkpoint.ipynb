{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab:  Logistic Regression for Gene Expression Data\n",
    "\n",
    "In this lab, we use logistic regression to predict biological characteristics (\"phenotypes\") from gene expression data.  In addition to the concepts in [breast cancer demo](./breast_cancer.ipynb), you will learn to:\n",
    "* Handle missing data\n",
    "* Perform multi-class logistic classification\n",
    "* Create a confusion matrix\n",
    "* Use L1-regularization for improved estimation in the case of sparse weights (Grad students only)\n",
    "\n",
    "## Background\n",
    "\n",
    "Genes are the basic unit in the DNA and encode blueprints for proteins.  When proteins are synthesized from a gene, the gene is said to \"express\".  Micro-arrays are devices that measure the expression levels of large numbers of genes in parallel.  By finding correlations between expression levels and phenotypes, scientists can identify possible genetic markers for biological characteristics.\n",
    "\n",
    "The data in this lab comes from:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "\n",
    "In this data, mice were characterized by three properties:\n",
    "* Whether they had down's syndrome (trisomy) or not\n",
    "* Whether they were stimulated to learn or not\n",
    "* Whether they had a drug memantine or a saline control solution.\n",
    "\n",
    "With these three choices, there are 8 possible classes for each mouse.  For each mouse, the expression levels were measured across 77 genes.  We will see if the characteristics can be predicted from the gene expression levels.  This classification could reveal which genes are potentially involved in Down's syndrome and if drugs and learning have any noticeable effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We begin by loading the standard modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pd.read_excel` command to read the data from \n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\n",
    "\n",
    "into a dataframe `df`.  Use the `index_col` option to specify that column 0 is the index.  Use the `df.head()` to print the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309_1</th>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_2</th>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "MouseID                                                                         \n",
       "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
       "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
       "\n",
       "         pCAMKII_N   pCREB_N    pELK_N   ...     pCFOS_N     SYP_N  H3AcK18_N  \\\n",
       "MouseID                                  ...                                    \n",
       "309_1     2.373744  0.232224  1.750936   ...    0.108336  0.427099   0.114783   \n",
       "309_2     2.292150  0.226972  1.596377   ...    0.104315  0.441581   0.111974   \n",
       "\n",
       "           EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
       "MouseID                                                                       \n",
       "309_1    0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
       "309_2    0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
       "\n",
       "[2 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "# df = ...\n",
    "df = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls', index_col=0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has missing values.  The site:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "\n",
    "has an excellent summary of methods to deal with missing values.  Following the techniques there, create a new data frame `df1` where the missing values in each column are filled with the mean values from the non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
      "MouseID                                                                         \n",
      "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
      "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
      "\n",
      "         pCAMKII_N   pCREB_N    pELK_N   ...     pCFOS_N     SYP_N  H3AcK18_N  \\\n",
      "MouseID                                  ...                                    \n",
      "309_1     2.373744  0.232224  1.750936   ...    0.108336  0.427099   0.114783   \n",
      "309_2     2.292150  0.226972  1.596377   ...    0.104315  0.441581   0.111974   \n",
      "\n",
      "           EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
      "MouseID                                                                       \n",
      "309_1    0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
      "309_2    0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
      "\n",
      "[2 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# df1 = ...\n",
    "df1 = df.fillna(df.mean())\n",
    "print(df1.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for Down's Syndrome\n",
    "\n",
    "We will first predict the binary class label in `df1['Genotype']` which indicates if the mouse has Down's syndrome or not.  Get the string values in `df1['Genotype'].values` and convert this to a numeric vector `y` with 0 or 1.  You may wish to use the `np.unique` command with the `return_inverse=True` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# y = ...\n",
    "val = df1['Genotype'].values\n",
    "y0 = np.unique(val, return_inverse=True)\n",
    "# y0 = np.unique(df1['Genotype'].values, return_inverse=True)\n",
    "# y = np.array(y0)\n",
    "y = y0[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predictors, get all but the last four columns of the dataframes.  Standardize the data matrix and call the standardized matrix `Xs`.  The predictors are the expression levels of the 77 genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.503643884 0.747193224 0.4301753 ..., 0.131790029 0.128185603 1.67565235]\n",
      " [0.51461708 0.689063548 0.411770344 ..., 0.13510297 0.1311187 1.743609645]\n",
      " [0.509183088 0.730246795 0.418308781 ..., 0.133361829 0.127431075\n",
      "  1.926426587]\n",
      " ..., \n",
      " [0.228699552 0.395179372 0.234118087 ..., 0.22919311 0.355213055\n",
      "  1.430825023]\n",
      " [0.221242406 0.412894376 0.243974133 ..., 0.251316506 0.365353187\n",
      "  1.404031233]\n",
      " [0.302625723 0.46105919 0.256564308 ..., 0.252994815 0.365278026\n",
      "  1.370999464]]\n",
      "[[ 0.31271112  0.5179336   2.2536689  ..., -1.41662394 -1.60789061\n",
      "   1.06590091]\n",
      " [ 0.35679793  0.28650133  1.8802795  ..., -1.32521803 -1.54684392\n",
      "   1.28029118]\n",
      " [ 0.33496588  0.45046461  2.01292763 ..., -1.37325709 -1.62359464\n",
      "   1.85703831]\n",
      " ..., \n",
      " [-0.79192771 -0.88354273 -1.72382963 ...,  1.27078193  3.11724261\n",
      "   0.29352469]\n",
      " [-0.82188815 -0.8130138  -1.52387571 ...,  1.88117889  3.32828966\n",
      "   0.2089962 ]\n",
      " [-0.49491588 -0.62125474 -1.26845332 ...,  1.92748438  3.32672533\n",
      "   0.10478825]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Apple/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Xs = ...\n",
    "x = np.array(df1)\n",
    "df_new = np.delete(x, [77,78,79,80], axis=1)\n",
    "X = np.array(df_new)\n",
    "Xs = preprocessing.scale(X)\n",
    "print(X)\n",
    "print(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `LogisticRegression` object `logreg` and `fit` the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the classifer.  That is, use the `logreg.predict` function to predict labels `yhat` and measure the fraction of time that the predictions match the true labels.  Below, we will properly measure the accuracy on cross-validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 1.000000\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "yhat = logreg.predict(Xs)\n",
    "acc = np.mean(yhat == y)\n",
    "print(\"Accuracy on training data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a stem plot of the coefficients, `W` in the logistic regression model.  You can get the coefficients from `logreg.coef_`, but you will need to reshape this to a 1D array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.66564187e+01   1.03669317e+02   1.21128686e+01  -2.83191017e+01\n",
      "  -9.03863404e-01   1.00481208e+01   6.00892488e+00  -7.74437280e+00\n",
      "   1.69823308e+01  -2.93138115e+01  -1.58867193e+01   1.15862688e+01\n",
      "   2.74192253e+01  -9.66888008e+00  -9.89275986e+00   6.15514485e+00\n",
      "   7.61167693e+00  -1.24474108e+01  -2.54185124e+01   9.69684762e+00\n",
      "  -6.90074838e+01  -1.71136594e+01  -1.86955341e+01  -4.34158122e+01\n",
      "  -5.64780342e+01   1.29286350e+01  -4.35131171e-01   1.23558305e+01\n",
      "   1.99575952e+01   3.77728424e-01   2.40363468e+01   5.02263679e+00\n",
      "   2.01144965e+01  -1.86321039e+01   5.09381935e+00   2.77318330e+00\n",
      "   1.03019424e+01  -2.48623071e+01  -5.86137891e+00  -3.89714291e+00\n",
      "  -7.32150398e+00   3.67851249e+01   5.48971526e+00   1.41955385e+01\n",
      "   1.15919575e+01   1.29823005e+01  -1.10951242e+01   1.51330266e+00\n",
      "   2.32562076e-01   9.50500213e+00   9.86491583e+00   2.73476414e-02\n",
      "  -1.27093516e+01  -6.59154292e+00   1.41695971e+01  -2.77816918e+00\n",
      "   4.36664792e+00  -9.50467161e+00  -2.01089561e+01   1.36710810e+00\n",
      "  -1.14650135e+01   1.11019978e+01  -6.91463621e+00   1.66888248e+01\n",
      "   3.19008155e+00   3.89195108e+00  -2.92064664e+00  -1.73826021e+01\n",
      "   3.56480218e+00   7.98881887e+00  -6.59154292e+00  -1.16757382e+00\n",
      "  -1.20333565e+01  -9.58818616e+00   4.81446017e+00  -1.65389062e+00\n",
      "   1.60252631e+01]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114daa940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "data = {'slope': np.squeeze(logreg.coef_)}\n",
    "dfslope = pd.DataFrame(data=data)\n",
    "dfslope\n",
    "\n",
    "for k in range(77):\n",
    "    plt.stem(dfslope)\n",
    "w = logreg.coef_\n",
    "w = np.array(w[0])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that `W[i]` is very large for a few components `i`.  These are the genes that are likely to be most involved in Down's Syndrome.  Although, we do not discuss it in this class, there are ways to force the logistic regression to return a sparse vector `W`.  \n",
    "\n",
    "Find the names of the genes for two components `i` where the magnitude of `W[i]` is largest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the names of the genes for two components i where the magnitude of W[i] is larges are as follows\n",
      "ITSN1_N TIAM1_N\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# print(dfslope)\n",
    "dfs = np.array(dfslope)\n",
    "dfs1 = np.reshape(dfs, (np.product(dfs.shape),))\n",
    "Isel = np.argsort(np.array(dfs1))[::-1][0:77]\n",
    "a = Isel[:1][0]\n",
    "b = Isel[1:2][0]\n",
    "X = list(df1)\n",
    "print('the names of the genes for two components i where the magnitude of W[i] is larges are as follows')\n",
    "print(X[a], X[b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The above meaured the accuracy on the training data.  It is more accurate to measure the accuracy on the test data.  Perform 10-fold cross validation and measure the average precision, recall and f1-score.  Note, that in performing the cross-validation, you will want to randomly permute the test and training sets using the `shuffle` option.  In this data set, all the samples from each class are bunched together, so shuffling is essential.  Print the mean precision, recall and f1-score and error rate across all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9481, SE=0.0118\n",
      "Recall =    0.9498, SE=0.0097\n",
      "f1 =        0.9486, SE=0.0088\n",
      "Accuracy =  0.9491, SE=0.0085\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "prec = []\n",
    "rec = []\n",
    "f1 = []\n",
    "acc = []\n",
    "for train, test in kf.split(Xs):            \n",
    "    # Get training and test data\n",
    "    Xtr = Xs[train,:]\n",
    "    ytr = y[train]\n",
    "    Xts = Xs[test,:]\n",
    "    yts = y[test]\n",
    "    \n",
    "    # Fit a model\n",
    "    logreg.fit(Xtr, ytr)\n",
    "    yhat = logreg.predict(Xts)\n",
    "    \n",
    "    # Measure performance\n",
    "    preci,reci,f1i,_= precision_recall_fscore_support(yts,yhat) \n",
    "    prec.append(preci)\n",
    "    rec.append(reci)\n",
    "    f1.append(f1i)\n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "\n",
    "# Take average values of the metrics\n",
    "precm = np.mean(prec)\n",
    "recm = np.mean(rec)\n",
    "f1m = np.mean(f1)\n",
    "accm= np.mean(acc)\n",
    "\n",
    "# Compute the standard errors\n",
    "prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
    "rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
    "f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "\n",
    "print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))\n",
    "print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
    "print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
    "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Now use the response variable in `df1['class']`.  This has 8 possible classes.  Use the `np.unique` funtion as before to convert this to a vector `y` with values 0 to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# y = ...\n",
    "val = df1['class'].values\n",
    "y0 = np.unique(val, return_inverse=True)\n",
    "y1 = y0[1]\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a multi-class logistic model by creating a `LogisticRegression` object, `logreg` and then calling the `logreg.fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(Xs, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 1.000000\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "yhat = logreg.predict(Xs)\n",
    "acc = np.mean(yhat == y1)\n",
    "print(\"Accuracy on training data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform 10-fold cross validation, and measure the confusion matrix `C` on the test data in each fold. You can use the `confustion_matrix` method in the `sklearn` package.  Add the confusion matrix counts across all folds and then normalize the rows of the confusion matrix so that they sum to one.  Thus, each element `C[i,j]` will represent the fraction of samples where `yhat==j` given `ytrue==i`.  Print the confusion matrix.  You can use the command\n",
    "\n",
    "    print(np.array_str(C, precision=4, suppress_small=True))\n",
    "    \n",
    "to create a nicely formatted print.  Also print the overall mean and SE of the test error rate across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.9444  0.      0.      0.1111  0.      0.      0.    ]\n",
      " [ 0.      0.      1.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      1.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      1.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      1.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      1.    ]]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 1.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.9286  0.      0.      0.      0.      0.0769  0.    ]\n",
      " [ 0.      0.      1.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      1.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      1.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      1.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      1.    ]]\n",
      "[[ 0.9333  0.05    0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.0667  0.95    0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      1.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      1.      0.      0.      0.      0.    ]\n",
      " [ 0.0667  0.      0.      0.      0.9474  0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      1.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      1.    ]]\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.]]\n",
      "[[ 0.9333  0.      0.      0.      0.0417  0.      0.      0.    ]\n",
      " [ 0.      1.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      1.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      1.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      1.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      1.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      1.    ]]\n",
      "[[ 0.9286  0.0714  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      1.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      1.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.0714  0.      0.      0.9286  0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      1.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      1.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      1.    ]]\n",
      "[[ 1.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.0714  0.9412  0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      1.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      1.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      1.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      1.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      1.    ]]\n",
      "[[ 1.      0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      1.      0.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      1.      0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      1.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.0833  0.      0.      0.9167  0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      1.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.      0.      0.      1.    ]]\n",
      "Precision = 0.9916, SE=0.0083\n",
      "Recall =    0.9919, SE=0.0072\n",
      "f1 =        0.9916, SE=0.0062\n",
      "Accuracy =  0.9907, SE=0.0028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# TODO\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "prec = []\n",
    "rec = []\n",
    "f1 = []\n",
    "acc = []\n",
    "\n",
    "for train, test in kf.split(Xs):            \n",
    "    # Get training and test data\n",
    "    Xtr = Xs[train,:]\n",
    "    ytr = y1[train]\n",
    "    Xts = Xs[test,:]\n",
    "    yts = y1[test]\n",
    "    \n",
    "    # Fit a model\n",
    "    logreg.fit(Xtr, ytr)\n",
    "    yhat = logreg.predict(Xts)\n",
    "    \n",
    "    preci, reci, f1i, _ = precision_recall_fscore_support(yts, yhat)\n",
    "    prec.append(preci)\n",
    "    rec.append(reci)\n",
    "    f1.append(f1i)\n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "    ci = confusion_matrix(yts, yhat)\n",
    "    ci = ci.astype(float)\n",
    "    ci = ci / np.sum(ci, axis = 1)\n",
    "    print(np.array_str(ci, precision=4, suppress_small=True))\n",
    "\n",
    "\n",
    "precm = np.mean(prec)\n",
    "recm = np.mean(rec)\n",
    "f1m = np.mean(f1)\n",
    "accm= np.mean(acc)\n",
    "\n",
    "prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
    "rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
    "f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "\n",
    "print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))\n",
    "print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
    "print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
    "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the logistic regression on the entire training data and get the weight coefficients.  This should be a 8 x 77 matrix.  Create a stem plot of the first row of this matrix to see the coefficients on each of the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 3 artists>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eedcf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg = linear_model.LogisticRegression(multi_class='multinomial',solver='newton-cg')\n",
    "logreg.fit(Xs, y1)           \n",
    "w = logreg.coef_\n",
    "y_plt = w[0]\n",
    "print(w.shape)\n",
    "plt.stem(range(w.shape[1]), y_plt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## L1-Regularization\n",
    "\n",
    "Graduate students only complete this section.\n",
    "\n",
    "In most genetic problems, only a limited number of the tested genes are likely influence any particular attribute.  Hence, we would expect that the weight coefficients in the logistic regression model should be sparse.  That is, they should be zero on any gene that plays no role in the particular attribute of interest.  Genetic analysis commonly imposes sparsity by adding an l1-penalty term.  Read the `sklearn` [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the `LogisticRegression` class to see how to set the l1-penalty and the inverse regularization strength, `C`.\n",
    "\n",
    "Using the model selection strategies from the [prostate cancer analysis demo](../model_sel/prostate.ipynb), use K-fold cross validation to select an appropriate inverse regularization strength.  \n",
    "* Use 10-fold cross validation \n",
    "* You should select around 20 values of `C`.  It is up to you find a good range.\n",
    "* Make appropriate plots and print out to display your results\n",
    "* How does the accuracy compare to the accuracy achieved without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96388889  0.96481481  0.96296296  0.96111111  0.96111111  0.96111111\n",
      "  0.95833333  0.95833333  0.95648148  0.95555556  0.95648148  0.95555556\n",
      "  0.95648148  0.9537037   0.95277778  0.9537037   0.95462963  0.9537037\n",
      "  0.95277778  0.95277778]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBERjwJBREQABYKIiHgUCCIiAsD/B2+7qimTvWa8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fe58470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy is 0.964815\n",
      "select c = 14.384499\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Create a k-fold cross validation object\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "c_alter = np.logspace(1, 4, 20)\n",
    "nd = 20\n",
    "prec2 = [[] for i in range(nd)]\n",
    "rec2 = [[] for i in range(nd)]\n",
    "f12 = [[] for i in range(nd)]\n",
    "acc2 = [[] for i in range(nd)]\n",
    "\n",
    "for isplit, Ind in enumerate(kf.split(Xs)):\n",
    "    Itr, Its = Ind\n",
    "    Xtr2 = Xs[Itr]\n",
    "    ytr2 = y[Itr]\n",
    "    Xts2 = Xs[Its]\n",
    "    yts2 = y[Its]\n",
    "    \n",
    "    for i, ci in enumerate(c_alter):\n",
    "        logreg2 = linear_model.LogisticRegression(penalty='l1',C=ci)\n",
    "        logreg2.fit(Xtr2, ytr2)\n",
    "        yhat2 = logreg2.predict(Xts2)\n",
    "        \n",
    "        preci, reci, f1i, _ = precision_recall_fscore_support(yts2, yhat2)\n",
    "        prec2[i].append(preci)\n",
    "        rec2[i].append(reci)\n",
    "        f12[i].append(f1i)\n",
    "        acci = np.mean(yhat2 == yts2)\n",
    "        acc2[i].append(acci)\n",
    "        \n",
    "precm2 = np.mean(prec2, axis=1)\n",
    "recm2 = np.mean(rec2, axis=1)\n",
    "f1m2 = np.mean(f12, axis=1)\n",
    "accm2 = np.mean(acc2, axis=1)\n",
    "\n",
    "prec_se2 = np.std(prec2, axis=1)/np.sqrt(nfold-1)\n",
    "rec_se2 = np.std(rec2, axis=1)/np.sqrt(nfold-1)\n",
    "f1_se2 = np.std(f12, axis=1)/np.sqrt(nfold-1)\n",
    "acc_se2 = np.std(acc2, axis=1)/np.sqrt(nfold-1)\n",
    "\n",
    "print(accm2)\n",
    "plt.plot(c_alter, accm2)\n",
    "plt.legend(['Precision', 'Recall', 'f1', 'Accuracy'])\n",
    "plt.xlabel('c')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "maxi = np.argsort(-accm2)[0]\n",
    "maxacc = accm2[maxi]\n",
    "ci = c_alter[maxi]\n",
    "print(\"max accuracy is {0:f}\".format(maxacc))\n",
    "print(\"select c = {0:f}\".format(ci))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the optimal `C`, fit the model on the entire training data with l1 regularization. Find the resulting weight matrix, `W_l1`.  Plot the first row of this weight matrix and compare it to the first row of the weight matrix without the regularization.  You should see that, with l1-regularization, the weight matrix is much more sparse and hence the roles of particular genes are more clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 3 artists>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAQJHwAi8f/RGjbZkCIBugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1220870f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg3 = linear_model.LogisticRegression(penalty='l1',C=ci)\n",
    "logreg3.fit(Xs, y)\n",
    "W = logreg3.coef_\n",
    "y_plt = W[0]\n",
    "print(W.shape)\n",
    "plt.stem(range(W.shape[1]), y_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
